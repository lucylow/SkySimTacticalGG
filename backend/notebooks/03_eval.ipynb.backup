{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation & Explainability\n",
    "\n",
    "Evaluate model and generate SHAP explanations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Load model\n",
    "    model_path = \"../app/models/momentum.pkl\"\n",
    "    if not Path(model_path).exists():\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "    # Load features\n",
    "    features_path = \"../data/features/team_features.parquet\"\n",
    "    if not Path(features_path).exists():\n",
    "        raise FileNotFoundError(f\"Features file not found: {features_path}\")\n",
    "    \n",
    "    print(f\"Loading features from {features_path}...\")\n",
    "    features = pd.read_parquet(features_path)\n",
    "    print(f\"Loaded {len(features)} feature rows\")\n",
    "    \n",
    "    # Prepare data\n",
    "    required_cols = [\"kills\", \"avg_kills_last_5\"]\n",
    "    missing_cols = [col for col in required_cols if col not in features.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    X = features[required_cols].fillna(0)\n",
    "    \n",
    "    if \"momentum_shift\" not in features.columns:\n",
    "        print(\"Warning: 'momentum_shift' column not found, skipping y variable\")\n",
    "        y = None\n",
    "    else:\n",
    "        y = features[\"momentum_shift\"].fillna(0)\n",
    "    \n",
    "    # Check if we have enough samples for SHAP\n",
    "    sample_size = 100\n",
    "    if len(X) < sample_size:\n",
    "        print(f\"Warning: Only {len(X)} samples available, using all samples for SHAP\")\n",
    "        sample_size = len(X)\n",
    "    \n",
    "    if sample_size == 0:\n",
    "        raise ValueError(\"No data available for SHAP analysis\")\n",
    "    \n",
    "    X_sample = X.sample(min(sample_size, len(X)), random_state=42)\n",
    "    \n",
    "    # SHAP explainer\n",
    "    print(\"Initializing SHAP explainer...\")\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        print(\"Computing SHAP values...\")\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        print(\"SHAP values computed successfully\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error during SHAP computation: {str(e)}\")\n",
    "    \n",
    "    # Summary plot\n",
    "    print(\"Generating SHAP summary plot...\")\n",
    "    try:\n",
    "        shap.summary_plot(shap_values, X_sample, show=False)\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        output_path = \"../data/shap_summary.png\"\n",
    "        output_dir = Path(output_path).parent\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"SHAP summary plot saved to {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error saving SHAP plot: {str(e)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: {str(e)}\")\n",
    "    print(\"Please ensure all required files exist before running this notebook.\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"ERROR: {str(e)}\")\n",
    "    print(\"Please check your data format and required columns.\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    print(f\"ERROR: {str(e)}\")\n",
    "    print(\"There was an error during model evaluation.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Unexpected error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Team Impact Score (TIS) - Example Calculation\n",
    "\n",
    "This example demonstrates how to calculate TIS for a player's recurring mistakes\n",
    "and quantify their impact on team performance.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ============================================================================\n",
    "# SAMPLE DATA: Player \"Alpha\" from a 30-round match (90 minutes)\n",
    "# ============================================================================\n",
    "\n",
    "mistakes_data = [\n",
    "    {\n",
    "        \"mistake_type\": \"predictable_positioning\",\n",
    "        \"player_id\": \"alpha_p1\",\n",
    "        \"instances\": 8,  # Occurred 8 times in the match\n",
    "        \"base_severity\": 0.7,  # From micro-analysis\n",
    "        \"outcome_correlation\": 0.65,  # 65% of rounds with this mistake were lost\n",
    "        \"round_phases\": {\"early\": 2, \"mid\": 4, \"late\": 2},  # Distribution\n",
    "        \"coordination_failure_rate\": 0.5,  # 50% of instances occurred with team coordination issues\n",
    "        \"cascading_mistake_rate\": 0.25,  # 25% triggered additional mistakes\n",
    "        \"context_distribution\": {\n",
    "            \"full_buy\": 3,\n",
    "            \"half_buy\": 3,\n",
    "            \"force_buy\": 2,\n",
    "            \"eco\": 0\n",
    "        },\n",
    "        \"score_pressure\": {\n",
    "            \"even\": 4,\n",
    "            \"down_2plus\": 3,\n",
    "            \"up_2plus\": 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"mistake_type\": \"late_utility_timing\",\n",
    "        \"player_id\": \"alpha_p1\",\n",
    "        \"instances\": 5,\n",
    "        \"base_severity\": 0.6,\n",
    "        \"outcome_correlation\": 0.8,  # 80% correlation with round loss\n",
    "        \"round_phases\": {\"early\": 0, \"mid\": 2, \"late\": 3},\n",
    "        \"coordination_failure_rate\": 0.6,\n",
    "        \"cascading_mistake_rate\": 0.4,\n",
    "        \"context_distribution\": {\n",
    "            \"full_buy\": 2,\n",
    "            \"half_buy\": 2,\n",
    "            \"force_buy\": 1,\n",
    "            \"eco\": 0\n",
    "        },\n",
    "        \"score_pressure\": {\n",
    "            \"even\": 2,\n",
    "            \"down_2plus\": 2,\n",
    "            \"up_2plus\": 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_round_phase_multiplier(phase_distribution: Dict[str, int], total: int) -> float:\n",
    "    \"\"\"Calculate weighted average round phase multiplier.\"\"\"\n",
    "    multipliers = {\"early\": 0.5, \"mid\": 1.0, \"late\": 1.5, \"clutch\": 2.0}\n",
    "    weighted_sum = sum(multipliers[phase] * count for phase, count in phase_distribution.items())\n",
    "    return weighted_sum / total if total > 0 else 1.0\n",
    "\n",
    "def calculate_economy_factor(context_dist: Dict[str, int], total: int) -> float:\n",
    "    \"\"\"Calculate weighted average economy factor.\"\"\"\n",
    "    factors = {\"full_buy\": 1.0, \"half_buy\": 1.2, \"force_buy\": 1.5, \"eco\": 0.8}\n",
    "    weighted_sum = sum(factors[econ] * count for econ, count in context_dist.items())\n",
    "    return weighted_sum / total if total > 0 else 1.0\n",
    "\n",
    "def calculate_score_pressure_factor(score_dist: Dict[str, int], total: int) -> float:\n",
    "    \"\"\"Calculate weighted average score pressure factor.\"\"\"\n",
    "    factors = {\"even\": 1.0, \"down_2plus\": 1.3, \"up_2plus\": 0.9}\n",
    "    weighted_sum = sum(factors[score] * count for score, count in score_dist.items())\n",
    "    return weighted_sum / total if total > 0 else 1.0\n",
    "\n",
    "def calculate_tactical_amplification(coord_rate: float, cascade_rate: float) -> float:\n",
    "    \"\"\"Calculate tactical amplification factor.\"\"\"\n",
    "    return 1.0 + (coord_rate * 0.5) + (cascade_rate * 0.3)\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TEAM IMPACT SCORE (TIS) CALCULATION - EXAMPLE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "match_minutes = 90  # Standard match length\n",
    "total_tis = 0.0\n",
    "\n",
    "for mistake in mistakes_data:\n",
    "    print(f\"Mistake Type: {mistake['mistake_type']}\")\n",
    "    print(f\"Player: {mistake['player_id']}\")\n",
    "    print(f\"Instances: {mistake['instances']}\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Calculate Mistake Impact (MI)\n",
    "    round_phase_mult = calculate_round_phase_multiplier(\n",
    "        mistake['round_phases'], \n",
    "        mistake['instances']\n",
    "    )\n",
    "    mi = mistake['base_severity'] * mistake['outcome_correlation'] * round_phase_mult\n",
    "    \n",
    "    print(f\"  Base Severity: {mistake['base_severity']}\")\n",
    "    print(f\"  Outcome Correlation: {mistake['outcome_correlation']}\")\n",
    "    print(f\"  Round Phase Multiplier: {round_phase_mult:.2f}\")\n",
    "    print(f\"  \u2192 Mistake Impact (MI): {mi:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # 2. Calculate Frequency (F) - normalized to per 90 minutes\n",
    "    frequency = mistake['instances'] / (match_minutes / 90)\n",
    "    print(f\"  Instances: {mistake['instances']}\")\n",
    "    print(f\"  Match Duration: {match_minutes} minutes\")\n",
    "    print(f\"  \u2192 Frequency (F): {frequency:.2f} per 90 minutes\")\n",
    "    print()\n",
    "    \n",
    "    # 3. Calculate Tactical Amplification (TA)\n",
    "    ta = calculate_tactical_amplification(\n",
    "        mistake['coordination_failure_rate'],\n",
    "        mistake['cascading_mistake_rate']\n",
    "    )\n",
    "    print(f\"  Coordination Failure Rate: {mistake['coordination_failure_rate']}\")\n",
    "    print(f\"  Cascading Mistake Rate: {mistake['cascading_mistake_rate']}\")\n",
    "    print(f\"  \u2192 Tactical Amplification (TA): {ta:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # 4. Calculate Context Weight (CW)\n",
    "    economy_factor = calculate_economy_factor(\n",
    "        mistake['context_distribution'],\n",
    "        mistake['instances']\n",
    "    )\n",
    "    score_factor = calculate_score_pressure_factor(\n",
    "        mistake['score_pressure'],\n",
    "        mistake['instances']\n",
    "    )\n",
    "    map_control_factor = 1.0  # Simplified for example\n",
    "    cw = economy_factor * score_factor * map_control_factor\n",
    "    \n",
    "    print(f\"  Economy Factor: {economy_factor:.3f}\")\n",
    "    print(f\"  Score Pressure Factor: {score_factor:.3f}\")\n",
    "    print(f\"  Map Control Factor: {map_control_factor:.3f}\")\n",
    "    print(f\"  \u2192 Context Weight (CW): {cw:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # 5. Calculate TIS contribution for this mistake type\n",
    "    tis_contribution = mi * frequency * ta * cw\n",
    "    total_tis += tis_contribution\n",
    "    \n",
    "    print(f\"  TIS Contribution = MI \u00d7 F \u00d7 TA \u00d7 CW\")\n",
    "    print(f\"                   = {mi:.3f} \u00d7 {frequency:.2f} \u00d7 {ta:.3f} \u00d7 {cw:.3f}\")\n",
    "    print(f\"                   = {tis_contribution:.3f} rounds lost per 90 minutes\")\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL RESULT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL TEAM IMPACT SCORE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total TIS: {total_tis:.3f} rounds lost per 90 minutes\")\n",
    "print()\n",
    "\n",
    "# Interpretation\n",
    "if total_tis < 0.5:\n",
    "    interpretation = \"LOW IMPACT - Mistakes are isolated and recoverable\"\n",
    "elif total_tis < 1.5:\n",
    "    interpretation = \"MODERATE IMPACT - Noticeable tactical weakness\"\n",
    "elif total_tis < 3.0:\n",
    "    interpretation = \"HIGH IMPACT - Significant team-level problem\"\n",
    "else:\n",
    "    interpretation = \"CRITICAL IMPACT - Major tactical vulnerability requiring immediate attention\"\n",
    "\n",
    "print(f\"Interpretation: {interpretation}\")\n",
    "print()\n",
    "\n",
    "# Expected impact over a full match\n",
    "expected_rounds_lost = total_tis * (match_minutes / 90)\n",
    "print(f\"Expected rounds lost per match (90 min): {expected_rounds_lost:.2f}\")\n",
    "print()\n",
    "\n",
    "# Business value translation\n",
    "print(\"=\" * 80)\n",
    "print(\"BUSINESS VALUE TRANSLATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"If corrected, this player's mistakes could save approximately:\")\n",
    "print(f\"  \u2022 {expected_rounds_lost:.1f} rounds per match\")\n",
    "print(f\"  \u2022 {expected_rounds_lost * 0.1:.2f} expected wins per 10 matches (assuming ~10% round-to-win conversion)\")\n",
    "print(f\"  \u2022 Significant improvement in team coordination and tactical execution\")\n",
    "print()\n",
    "\n",
    "# Actionable insight\n",
    "print(\"=\" * 80)\n",
    "print(\"ACTIONABLE INSIGHT\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Priority Focus Areas:\")\n",
    "for i, mistake in enumerate(mistakes_data, 1):\n",
    "    phase_mult = calculate_round_phase_multiplier(mistake['round_phases'], mistake['instances'])\n",
    "    mi = mistake['base_severity'] * mistake['outcome_correlation'] * phase_mult\n",
    "    freq = mistake['instances'] / (match_minutes / 90)\n",
    "    ta = calculate_tactical_amplification(\n",
    "        mistake['coordination_failure_rate'],\n",
    "        mistake['cascading_mistake_rate']\n",
    "    )\n",
    "    econ = calculate_economy_factor(mistake['context_distribution'], mistake['instances'])\n",
    "    score = calculate_score_pressure_factor(mistake['score_pressure'], mistake['instances'])\n",
    "    cw = econ * score * 1.0\n",
    "    contribution = mi * freq * ta * cw\n",
    "    \n",
    "    print(f\"{i}. {mistake['mistake_type']}: {contribution:.3f} rounds/90min\")\n",
    "    print(f\"   \u2192 Focus on {'late-round' if phase_mult > 1.2 else 'mid-round'} execution\")\n",
    "    print(f\"   \u2192 Address coordination in {int(mistake['coordination_failure_rate']*100)}% of instances\")\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}